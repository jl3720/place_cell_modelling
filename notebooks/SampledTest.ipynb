{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jl3720/place_cell_modelling/blob/main/SampledTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import tensorflow as tf\n",
        "import math, os, glob, re\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "ss = StandardScaler() \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#from numpy.core.fromnumeric import argmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "szaOu4uZ1oxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7kQV_o4wAm7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b637f165-bfae-4cba-b6fa-5beffb91ceed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/A Project/Data/Images'\n",
        "images = pd.Series(glob.glob(os.path.join(path,\"*/*.png\"),recursive=True),name= 'image')\n"
      ],
      "metadata": {
        "id": "8zTCZS0XE-mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_series = images[::5]\n",
        "images.drop(index = [i for i in range(0,len(images),5)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge5W-WDFXiN",
        "outputId": "0e304b2e-49ee-4948-b152-bafd004446a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        /content/drive/MyDrive/A Project/Data/Images/P...\n",
              "2        /content/drive/MyDrive/A Project/Data/Images/P...\n",
              "3        /content/drive/MyDrive/A Project/Data/Images/P...\n",
              "4        /content/drive/MyDrive/A Project/Data/Images/P...\n",
              "6        /content/drive/MyDrive/A Project/Data/Images/P...\n",
              "                               ...                        \n",
              "11112    /content/drive/MyDrive/A Project/Data/Images/R...\n",
              "11113    /content/drive/MyDrive/A Project/Data/Images/R...\n",
              "11114    /content/drive/MyDrive/A Project/Data/Images/R...\n",
              "11116    /content/drive/MyDrive/A Project/Data/Images/R...\n",
              "11117    /content/drive/MyDrive/A Project/Data/Images/R...\n",
              "Name: image, Length: 8894, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###I used a block to get these values, I'm going to try running it with the actual person and see what max and min values I can get\n",
        "\n",
        "ymin: -1695\n",
        "\n",
        "ymax: -220\n",
        "\n",
        "xmin: 200\n",
        "\n",
        "xmax: 2610\n",
        "\n"
      ],
      "metadata": {
        "id": "vWtrl9I6trmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing\n"
      ],
      "metadata": {
        "id": "FZa9SPgSMdM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating Dataframe with imagepaths in one column and the normalized x,y and theta values"
      ],
      "metadata": {
        "id": "czakvUz1MhNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(series):\n",
        "  \n",
        "\n",
        "\n",
        "  # images = glob.glob(os.path.join(path,\"*/*.png\"),recursive=True)\n",
        "  # images_series = pd.Series(images,name = 'image')\n",
        "  # #x_train = np.zeros((len(images),3))\n",
        "\n",
        "  df = pd.DataFrame({'image':series})\n",
        "\n",
        "  def get_coordinates(filename):\n",
        "    xmax = 2610\n",
        "    xmin = 200\n",
        "    ymax = 1695\n",
        "    ymin = 220\n",
        "    match = re.findall(r\"(X|Y)=(-?\\d+\\.\\d+)\", filename) \n",
        "    theta, x, y = [float(i[-1]) for i in match]\n",
        "\n",
        "    #Scaling x,y and theta to be between 0 and 1\n",
        "    if theta < 0:\n",
        "      theta +=360\n",
        "    theta /=360\n",
        "    # if x> xmax or x <xmin:\n",
        "    #   print(\"x = \",x)\n",
        "    x = (x-xmin)/(xmax-xmin)\n",
        "    y*= -1\n",
        "    # if y>ymax or y<ymin:\n",
        "    #   print(\"y =\",y)\n",
        "    y = (y -ymin)/(ymax-ymin)\n",
        "    return np.array([x,y,theta])\n",
        "\n",
        "  x_train = df['image'].apply(lambda x: pd.Series(get_coordinates(x)))\n",
        "  df = df.join(x_train)\n",
        "  df = df.rename(columns={0: 'x', 1: 'y', 2: 'theta'})\n",
        "  return df\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "86sTm7XSTr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = get_dataframe(images)\n",
        "test_df = get_dataframe(test_series)"
      ],
      "metadata": {
        "id": "iTKMswKmwhs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating dataframe"
      ],
      "metadata": {
        "id": "ltoM03UzMuHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for correct scaling"
      ],
      "metadata": {
        "id": "k2A6Xqtx2RHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_df['x']),min(train_df['x'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H64WR99LNWFM",
        "outputId": "b9bbfb87-5227-404f-e0a2-6653d74b4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.106795020746888, -0.01521535269709544)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Set picture dimensions here"
      ],
      "metadata": {
        "id": "XTnVbl08aE0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim1 = 128\n",
        "dim2 = 128"
      ],
      "metadata": {
        "id": "vVAELF8-aLkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to get about 10,000"
      ],
      "metadata": {
        "id": "fIKFLjAyxKFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    #validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "  \n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "rqz7EJw1-TG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_file(filepath):\n",
        "    if os.path.isfile(filepath) and \".png\" in filepath:\n",
        "        return filepath\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "train_df['image'] = train_df['image'].apply(validate_file)\n",
        "train_df.dropna(subset=['image'], inplace=True)"
      ],
      "metadata": {
        "id": "NtmErlnzKbaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['image'] = test_df['image'].apply(validate_file)\n",
        "test_df.dropna(subset=['image'], inplace=True)"
      ],
      "metadata": {
        "id": "rGP9sCStNbST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 32"
      ],
      "metadata": {
        "id": "-wswVij-vgRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image',\n",
        "    y_col=['x','y','theta'],\n",
        "    target_size=(dim1, dim2),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=bs,\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "    #subset='training',\n",
        "    #validate_filenames = False)\n",
        "\n",
        "\n",
        "# val_images = train_generator.flow_from_dataframe(\n",
        "#     dataframe=train_df,\n",
        "#     x_col='image',\n",
        "#     y_col=['x','y','theta'],\n",
        "#     target_size=(dim1, dim2),\n",
        "#     color_mode='rgb',\n",
        "#     class_mode='raw',\n",
        "#     batch_size=32,\n",
        "#     shuffle=True,\n",
        "#     seed=42,\n",
        "#     subset='validation',\n",
        "#     #validate_filenames = False)\n",
        "\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image',\n",
        "    y_col=['x','y','theta'],\n",
        "    target_size=(dim1, dim2),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=bs,\n",
        "    shuffle=False)\n",
        "    #validate_filenames = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ww3yLJe-T2F",
        "outputId": "547674e1-44e3-4684-a7d7-cf66afc26feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11118 validated image filenames.\n",
            "Found 2224 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can split train/validation/test by leaving out paths. "
      ],
      "metadata": {
        "id": "xLfWbyQOsOQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Architecture"
      ],
      "metadata": {
        "id": "JDEn-YorLdm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(dim1,dim2):\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  # Input layer\n",
        "  model.add(tf.keras.layers.Input(shape=(dim1, dim2, 3)))\n",
        "\n",
        "  # Convolutional layer 1\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "  # Pooling layer 1\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  \n",
        "  #Dropout Layer \n",
        "  model.add(tf.keras.layers.Dropout(0.4)) \n",
        "\n",
        "  # Convolutional layer 2\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "  # Pooling layer 2\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  #Dropout Layer \n",
        "  model.add(tf.keras.layers.Dropout(0.4)) \n",
        "\n",
        "  # Convolutional layer 3\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  \n",
        "  # Pooling layer 3\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  #Dropout Layer \n",
        "  model.add(tf.keras.layers.Dropout(0.4)) \n",
        "\n",
        "  # Convolutional layer 4\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "  # Pooling layer 4\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  #Dropout Layer \n",
        "  model.add(tf.keras.layers.Dropout(0.4)) \n",
        "\n",
        "  # Flatten the feature maps\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  # 1-2 Flat Layers\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "  #model.add(tf.keras.layers.Dropout(0.25)) \n",
        "\n",
        "  model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "  #model.add(tf.keras.layers.Dropout(0.25)) \n",
        "\n",
        "  #Place Cell Behaviour\n",
        "  model.add(tf.keras.layers.Dense(32, activation='linear'))\n",
        "\n",
        "  #Decoding\n",
        "  model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(3,activation= 'linear'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mse')  #,metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "jOo1aaxD1NJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WE can halve the numbers"
      ],
      "metadata": {
        "id": "al4li_E3wcBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = make_model(dim1,dim2)\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "bdO4kpNj1Phz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4fdd7b-137b-4239-ed99-a03267a87da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 590,899\n",
            "Trainable params: 590,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving Model\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/A Project/Scripts/Hyperparameters/Filters/cnn_filter_size_4x4/Model Epochs/model-{epoch:02d}.h5\", save_best_only=False, save_weights_only=False, period=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "pgJEtSBXdN1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Patience = 10\n",
        "history = cnn.fit(\n",
        "    train_images,\n",
        "    validation_data=test_images,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=Patience,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "bW7U20gjD9rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166838bd-4366-4e6d-b636-78d1e2c5b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "348/348 [==============================] - 3479s 10s/step - loss: 0.0869 - val_loss: 0.1020\n",
            "Epoch 2/100\n",
            "348/348 [==============================] - 716s 2s/step - loss: 0.0764 - val_loss: 0.0973\n",
            "Epoch 3/100\n",
            "348/348 [==============================] - 739s 2s/step - loss: 0.0729 - val_loss: 0.0902\n",
            "Epoch 4/100\n",
            "348/348 [==============================] - 734s 2s/step - loss: 0.0676 - val_loss: 0.0867\n",
            "Epoch 5/100\n",
            "348/348 [==============================] - 733s 2s/step - loss: 0.0622 - val_loss: 0.0817\n",
            "Epoch 6/100\n",
            "348/348 [==============================] - 720s 2s/step - loss: 0.0568 - val_loss: 0.0616\n",
            "Epoch 7/100\n",
            "348/348 [==============================] - 716s 2s/step - loss: 0.0504 - val_loss: 0.0687\n",
            "Epoch 8/100\n",
            "348/348 [==============================] - 727s 2s/step - loss: 0.0464 - val_loss: 0.0544\n",
            "Epoch 9/100\n",
            "348/348 [==============================] - 708s 2s/step - loss: 0.0441 - val_loss: 0.0532\n",
            "Epoch 10/100\n",
            "348/348 [==============================] - 714s 2s/step - loss: 0.0403 - val_loss: 0.0489\n",
            "Epoch 11/100\n",
            "348/348 [==============================] - 717s 2s/step - loss: 0.0382 - val_loss: 0.0409\n",
            "Epoch 12/100\n",
            "348/348 [==============================] - 708s 2s/step - loss: 0.0361 - val_loss: 0.0433\n",
            "Epoch 13/100\n",
            "348/348 [==============================] - 736s 2s/step - loss: 0.0340 - val_loss: 0.0388\n",
            "Epoch 14/100\n",
            "348/348 [==============================] - 714s 2s/step - loss: 0.0329 - val_loss: 0.0377\n",
            "Epoch 15/100\n",
            "348/348 [==============================] - 719s 2s/step - loss: 0.0308 - val_loss: 0.0395\n",
            "Epoch 16/100\n",
            "348/348 [==============================] - 711s 2s/step - loss: 0.0304 - val_loss: 0.0303\n",
            "Epoch 17/100\n",
            "348/348 [==============================] - 718s 2s/step - loss: 0.0302 - val_loss: 0.0343\n",
            "Epoch 18/100\n",
            "348/348 [==============================] - 722s 2s/step - loss: 0.0283 - val_loss: 0.0317\n",
            "Epoch 19/100\n",
            "348/348 [==============================] - 712s 2s/step - loss: 0.0273 - val_loss: 0.0295\n",
            "Epoch 20/100\n",
            "348/348 [==============================] - 736s 2s/step - loss: 0.0261 - val_loss: 0.0231\n",
            "Epoch 21/100\n",
            "348/348 [==============================] - 722s 2s/step - loss: 0.0250 - val_loss: 0.0243\n",
            "Epoch 22/100\n",
            "348/348 [==============================] - 727s 2s/step - loss: 0.0254 - val_loss: 0.0322\n",
            "Epoch 23/100\n",
            "348/348 [==============================] - 747s 2s/step - loss: 0.0247 - val_loss: 0.0299\n",
            "Epoch 24/100\n",
            "348/348 [==============================] - 715s 2s/step - loss: 0.0239 - val_loss: 0.0206\n",
            "Epoch 25/100\n",
            "348/348 [==============================] - 737s 2s/step - loss: 0.0238 - val_loss: 0.0283\n",
            "Epoch 26/100\n",
            "348/348 [==============================] - 722s 2s/step - loss: 0.0233 - val_loss: 0.0175\n",
            "Epoch 27/100\n",
            "348/348 [==============================] - 719s 2s/step - loss: 0.0224 - val_loss: 0.0230\n",
            "Epoch 28/100\n",
            "348/348 [==============================] - 719s 2s/step - loss: 0.0227 - val_loss: 0.0181\n",
            "Epoch 29/100\n",
            "134/348 [==========>...................] - ETA: 6:21 - loss: 0.0211"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "icpKRuKP2Hz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('/content/drive/MyDrive/A Project/CNN Stuff]'\\/cnn_what_a_great_start')"
      ],
      "metadata": {
        "id": "u10hev6KJAaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true = test_images.labels\n",
        "pred = cnn.predict(test_images)"
      ],
      "metadata": {
        "id": "lm0tFgjYHHnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look into bootstrapping and check vs. random (completely random)"
      ],
      "metadata": {
        "id": "Cf3mV7ATuBPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "mse_x = mse(true[:,0],pred[:,0])\n",
        "mse_y = mse(true[:,1],pred[:,1])\n",
        "mse_theta = mse(true[:,2],pred[:,2])\n",
        "amse = (mse_x + mse_y + mse_theta)/3\n",
        "rmse = np.sqrt(amse)\n",
        "print(mse_x,mse_y,mse_theta,sep = '\\n')\n",
        "amse,rmse"
      ],
      "metadata": {
        "id": "oPbKdkCCT5is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn # Your model\n",
        "\n",
        "# Find the first convolutional layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        break\n",
        "\n",
        "# Get the layer's configuration\n",
        "config = layer.get_config()\n",
        "\n",
        "# Extract the filter size, number of filters, and padding\n",
        "filter_size = config['kernel_size']\n",
        "num_filters = config['filters']\n",
        "padding = config['padding']\n",
        "loss_fn = model.loss\n",
        "data = [mse_x,mse_y,mse_theta,amse,rmse,len(history.history['loss']),Patience,bs,filter_size,num_filters,padding,loss_fn]\n",
        "print(data)"
      ],
      "metadata": {
        "id": "OhOKUY_BTS9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('data.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the rows of data to the file\n",
        "    for row in data:\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "C2u5dL0XVUp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one graph of absolute distance error \n",
        "\n",
        "one graph of angle error \n",
        "\n",
        "do those graphs for each type (CNN vs. random vs. bootstrapping)"
      ],
      "metadata": {
        "id": "nxyb7vqSuUK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(true[:,0])\n",
        "plt.plot(pred[:,0])"
      ],
      "metadata": {
        "id": "B56NNP2dQuhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(true[:,1])\n",
        "plt.plot(pred[:,1])\n"
      ],
      "metadata": {
        "id": "i_8rL4lpYUus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(true[:,2])\n",
        "plt.plot(pred[:,2])"
      ],
      "metadata": {
        "id": "pb37UIDIdnj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}